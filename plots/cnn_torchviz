digraph {
	graph [size="16.95,16.95"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	137747495577712 [label="
 (32, 10)" fillcolor=darkolivegreen1]
	137747500479776 [label=SoftmaxBackward0]
	137747495442448 -> 137747500479776
	137747495442448 [label=AddmmBackward0]
	137747495442640 -> 137747495442448
	137747495575600 [label="fc2.bias
 (10)" fillcolor=lightblue]
	137747495575600 -> 137747495442640
	137747495442640 [label=AccumulateGrad]
	137747495443264 -> 137747495442448
	137747495443264 [label=MulBackward0]
	137747495442496 -> 137747495443264
	137747495442496 [label=ReluBackward0]
	137747495449456 -> 137747495442496
	137747495449456 [label=AddmmBackward0]
	137747495449312 -> 137747495449456
	137747495575408 [label="fc1.bias
 (500)" fillcolor=lightblue]
	137747495575408 -> 137747495449312
	137747495449312 [label=AccumulateGrad]
	137747495449360 -> 137747495449456
	137747495449360 [label=ViewBackward0]
	137747495443408 -> 137747495449360
	137747495443408 [label=ReluBackward0]
	137747495448496 -> 137747495443408
	137747495448496 [label=NativeBatchNormBackward0]
	137747495450944 -> 137747495448496
	137747495450944 [label=ConvolutionBackward0]
	137747495449168 -> 137747495450944
	137747495449168 [label=MaxPool2DWithIndicesBackward0]
	137747495449888 -> 137747495449168
	137747495449888 [label=ReluBackward0]
	137747495450320 -> 137747495449888
	137747495450320 [label=NativeBatchNormBackward0]
	137747495450272 -> 137747495450320
	137747495450272 [label=ConvolutionBackward0]
	137747495450752 -> 137747495450272
	137747495450752 [label=MaxPool2DWithIndicesBackward0]
	137747495450656 -> 137747495450752
	137747495450656 [label=ReluBackward0]
	137747495450800 -> 137747495450656
	137747495450800 [label=NativeBatchNormBackward0]
	137747495450368 -> 137747495450800
	137747495450368 [label=ConvolutionBackward0]
	137747495445328 -> 137747495450368
	137747495445328 [label=NativeBatchNormBackward0]
	137747495445184 -> 137747495445328
	137747495572720 [label="batch_norm_0.weight
 (3)" fillcolor=lightblue]
	137747495572720 -> 137747495445184
	137747495445184 [label=AccumulateGrad]
	137747495445376 -> 137747495445328
	137747495572816 [label="batch_norm_0.bias
 (3)" fillcolor=lightblue]
	137747495572816 -> 137747495445376
	137747495445376 [label=AccumulateGrad]
	137747495445424 -> 137747495450368
	137747495573296 [label="conv_layer_1.weight
 (16, 3, 5, 5)" fillcolor=lightblue]
	137747495573296 -> 137747495445424
	137747495445424 [label=AccumulateGrad]
	137747495450464 -> 137747495450368
	137747495573392 [label="conv_layer_1.bias
 (16)" fillcolor=lightblue]
	137747495573392 -> 137747495450464
	137747495450464 [label=AccumulateGrad]
	137747495450512 -> 137747495450800
	137747495573488 [label="batch_norm_1.weight
 (16)" fillcolor=lightblue]
	137747495573488 -> 137747495450512
	137747495450512 [label=AccumulateGrad]
	137747495451376 -> 137747495450800
	137747495573584 [label="batch_norm_1.bias
 (16)" fillcolor=lightblue]
	137747495573584 -> 137747495451376
	137747495451376 [label=AccumulateGrad]
	137747495450416 -> 137747495450272
	137747495573968 [label="conv_layer_2.weight
 (32, 16, 5, 5)" fillcolor=lightblue]
	137747495573968 -> 137747495450416
	137747495450416 [label=AccumulateGrad]
	137747495450608 -> 137747495450272
	137747495574064 [label="conv_layer_2.bias
 (32)" fillcolor=lightblue]
	137747495574064 -> 137747495450608
	137747495450608 [label=AccumulateGrad]
	137747495449984 -> 137747495450320
	137747495574160 [label="batch_norm_2.weight
 (32)" fillcolor=lightblue]
	137747495574160 -> 137747495449984
	137747495449984 [label=AccumulateGrad]
	137747495449024 -> 137747495450320
	137747495574256 [label="batch_norm_2.bias
 (32)" fillcolor=lightblue]
	137747495574256 -> 137747495449024
	137747495449024 [label=AccumulateGrad]
	137747495449600 -> 137747495450944
	137747495574640 [label="conv_layer_3.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	137747495574640 -> 137747495449600
	137747495449600 [label=AccumulateGrad]
	137747495451088 -> 137747495450944
	137747495574736 [label="conv_layer_3.bias
 (64)" fillcolor=lightblue]
	137747495574736 -> 137747495451088
	137747495451088 [label=AccumulateGrad]
	137747495451328 -> 137747495448496
	137747495574832 [label="batch_norm_3.weight
 (64)" fillcolor=lightblue]
	137747495574832 -> 137747495451328
	137747495451328 [label=AccumulateGrad]
	137747495450224 -> 137747495448496
	137747495574928 [label="batch_norm_3.bias
 (64)" fillcolor=lightblue]
	137747495574928 -> 137747495450224
	137747495450224 [label=AccumulateGrad]
	137747495442304 -> 137747495449456
	137747495442304 [label=TBackward0]
	137747495450896 -> 137747495442304
	137747495575312 [label="fc1.weight
 (500, 576)" fillcolor=lightblue]
	137747495575312 -> 137747495450896
	137747495450896 [label=AccumulateGrad]
	137747495442544 -> 137747495442448
	137747495442544 [label=TBackward0]
	137747495449504 -> 137747495442544
	137747495575504 [label="fc2.weight
 (10, 500)" fillcolor=lightblue]
	137747495575504 -> 137747495449504
	137747495449504 [label=AccumulateGrad]
	137747500479776 -> 137747495577712
}
